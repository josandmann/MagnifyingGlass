{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from numpy import random as rng\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import skimage.io as ski\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as ks\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.data.experimental import AUTOTUNE\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 11:09:05.510945: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-15 11:09:05.816989: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:968] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-05-15 11:09:05.820635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:09:00.0 name: NVIDIA GeForce GTX 1660 SUPER computeCapability: 7.5\n",
      "coreClock: 1.83GHz coreCount: 22 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-05-15 11:09:05.820722: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-05-15 11:09:05.858584: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2022-05-15 11:09:05.880151: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-15 11:09:05.885320: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-15 11:09:05.923629: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-05-15 11:09:05.928866: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-05-15 11:09:05.992151: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-05-15 11:09:05.992330: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:968] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-05-15 11:09:05.992368: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:968] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-05-15 11:09:05.992375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '/mnt/d/cardimagescans'\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds a dictionary containing all set codes and sizes of\n",
    "# png files of cards in the database\n",
    "# WARNING: Long runtime. Skip if set_dict.pickle is available\n",
    "sets = os.listdir(data_path)\n",
    "set_dict = {}\n",
    "with open('set_dict.pickle', 'rb') as f:\n",
    "    set_dict = pkl.load(f)\n",
    "for s in sets:\n",
    "    cardsinset = os.listdir(os.path.join(data_path, s))\n",
    "    if s in set_dict.keys() and len(cardsinset) == len(set_dict.get(s)):\n",
    "        pass\n",
    "    else:\n",
    "        set_dict[s] = []\n",
    "        print('Listing set {}'.format(s))\n",
    "        for card in cardsinset:\n",
    "            image = cv2.imread(os.path.join(data_path, s, card))\n",
    "            if type(image) == type(None):\n",
    "                print('Error loading {} {}'.format(s, card))\n",
    "            h, w = image.shape[:2]\n",
    "            set_dict[s].append([h,w])\n",
    "\n",
    "with open('set_dict.pickle', mode='wb') as f:\n",
    "    pkl.dump(set_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load set_dict.pickle to avoid long runtime\n",
    "with open('set_dict.pickle', 'rb') as f:\n",
    "    set_dict = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns true if all card images have the same hxw size\n",
    "def uniform_cardsize(setname, set_dict):\n",
    "    s = np.array(set_dict.get(setname, False))\n",
    "    if False in s:\n",
    "        return False\n",
    "    return np.size([list(set(s[:,0])), list(set(s[:,1]))]) == 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random horizontal cutoff\n",
    "def random_h_shift(image, ratio=0.5):\n",
    "    height, width = image.shape[:2]\n",
    "    cutoff = rng.uniform(-ratio, ratio)\n",
    "    if cutoff >0:\n",
    "        shifted = image[:, :int(width-width*cutoff), :]\n",
    "    if cutoff <0:\n",
    "        shifted = image[:, int(-1*width*cutoff):, :]\n",
    "    resized = cv2.resize(shifted, (width, height), cv2.INTER_CUBIC)\n",
    "    return resized\n",
    "\n",
    "# random vertical cutoff\n",
    "def random_v_shift(image):\n",
    "    img_height = image.shape[0]\n",
    "    cutoff = rng.choice(range(0-int(img_height/2), int(img_height/2)))\n",
    "    if cutoff >= 0:\n",
    "        shifted = image[cutoff:]\n",
    "    else:\n",
    "        shifted = image[:cutoff]\n",
    "    resized = cv2.resize(shifted, image.shape[1::-1], cv2.INTER_CUBIC)\n",
    "    return resized\n",
    "\n",
    "# randomly increase or decrease brightness\n",
    "def random_brightness(image, low=.05, high=3):\n",
    "    value = rng.uniform(low,high)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv = np.array(hsv, dtype=np.float64)\n",
    "    hsv[:,:,1] = hsv[:,:,1]*value # scale values\n",
    "    hsv[:,:,1][hsv[:,:,1]>255] = 255 # clip high values\n",
    "    hsv[:,:,2] = hsv[:,:,2]*value\n",
    "    hsv[:,:,2][hsv[:,:,2]>255] = 255\n",
    "    hsv = np.array(hsv, dtype = np.uint8)\n",
    "    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img\n",
    "\n",
    "# add random blur\n",
    "def random_blur(image, kernel_min=5, kernel_max=30):\n",
    "    kernel_size = tuple(np.random.choice(range(kernel_min, kernel_max), size=2))\n",
    "    img = cv2.blur(image, kernel_size, cv2.BORDER_DEFAULT)\n",
    "    return img\n",
    "\n",
    "# add random contrast changes\n",
    "def random_contrast(image, low=0.5, high=3):\n",
    "    #print(image[42])\n",
    "    value = rng.uniform(low, high)\n",
    "    #print(value)\n",
    "    img = np.multiply(np.array(image).astype(np.int32), value)\n",
    "    #print(np.equal(img, image))\n",
    "    img[img>255] = 255\n",
    "    return img.astype('uint8')\n",
    "\n",
    "\n",
    "# TODO: implement image preprocessing\n",
    "# def augment(image):\n",
    "#     result = np.zeros((101,1040,745,3))\n",
    "#     index = 0\n",
    "#     for i in range(1,11):\n",
    "#         result[index] = random_h_shift(image) # h_shift\n",
    "#         index +=1\n",
    "#         result[index] = random_v_shift(image) # v_shift\n",
    "#         index +=1\n",
    "#         result[index] = random_blur(image, kernel_min=2*i, kernel_max=5+2*i) # blur\n",
    "#         index +=1\n",
    "#         result[index] = random_h_shift(random_v_shift(image)) # h&v shift\n",
    "#         index +=1\n",
    "#     for i in range(5):\n",
    "#         a = 1 + 3*i\n",
    "#         b = 5 + 5*i\n",
    "#         result[index] = random_brightness(image, 0.1, 0.99) # lower brightness\n",
    "#         index +=1\n",
    "#         result[index] = random_brightness(image, 1.1, 3) # higher brightness\n",
    "#         index +=1\n",
    "#         result[index] = random_blur(\n",
    "#             random_brightness(image, 0.1, 0.99), a, b) # lower brightness + blur\n",
    "#         index +=1\n",
    "#         result[index] = random_blur(\n",
    "#             random_brightness(image, 1.1, 3), a, b) # higher brightness + blur\n",
    "#         index +=1\n",
    "#         result[index] = random_contrast(image, 0.2, 0.99) # lower contrast\n",
    "#         index +=1\n",
    "#         result[index] = random_contrast(image, 1.01, 3) # higher contrast\n",
    "#         index +=1\n",
    "#         result[index] = random_blur(\n",
    "#             random_contrast(image, 0.2, 0.99), a, b) # lower contrast + blur\n",
    "#         index +=1\n",
    "#         result[index] = random_blur(\n",
    "#             random_contrast(image, 1.01, 3), a, b) # higher contrast + blur\n",
    "#         index +=1\n",
    "#         result[index] = random_v_shift(random_h_shift(\n",
    "#             random_blur(random_contrast(image, 0.2, 0.99), a, b))) # lower contrast + blur + hv shift\n",
    "#         index +=1\n",
    "#         result[index] = random_v_shift(random_h_shift(\n",
    "#             random_blur(random_contrast(image, 1.01, 3), a, b))) # higher contrast + blur + hv shift\n",
    "#         index +=1\n",
    "#         result[index] = random_h_shift(random_v_shift(\n",
    "#             random_blur(random_brightness(image, 0.1, 0.99), a, b) # lower brightness + blur + hv shift\n",
    "#         ))\n",
    "#         index +=1\n",
    "#         result[index] = random_h_shift(random_v_shift(\n",
    "#             random_blur(random_brightness(image, 1.1, 3), a, b) # higher brightness + blur + hv shift\n",
    "#         ))\n",
    "#         index +=1\n",
    "#     result[index] = image # append original image as the 101st in the dataset\n",
    "#     return np.array(result)\n",
    "\n",
    "# apply a random augmentation to the image\n",
    "# intended to be a simple, reusable function that can be applied \n",
    "# multiple times to increase difficulty\n",
    "def random_augment(image, choice=False):\n",
    "    if not choice:\n",
    "        choice = rng.choice(range(8))\n",
    "    if choice == 0:\n",
    "        return random_h_shift(image)\n",
    "    if choice == 1:\n",
    "        return random_v_shift(image)\n",
    "    if choice == 2:\n",
    "        return random_brightness(image, low= 0.05, high=0.99)\n",
    "    if choice == 3:\n",
    "        return random_brightness(image, low=1.01, high=3)\n",
    "    if choice == 4:\n",
    "        return random_blur(image, kernel_min=5, kernel_max=15)\n",
    "    if choice == 5:\n",
    "        return random_blur(image, kernel_min=15, kernel_max=30)\n",
    "    if choice == 6:\n",
    "        return random_contrast(image, low=0.2, high=0.8)\n",
    "    if choice == 7:\n",
    "        return random_contrast(image, low=1.2, high=3)\n",
    "\n",
    "def augment(image, runs=3):\n",
    "    img = image\n",
    "    for i in range(runs):\n",
    "        img = random_augment(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "# TODO: implement dataset generation using preprocessing\n",
    "def make_dataset(setcodes, data_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for code in setcodes:\n",
    "        set_dir = os.listdir(os.path.join(data_path, code))\n",
    "        for card in set_dir:\n",
    "            image = cv2.imread(os.path.join(data_path, code, card))\n",
    "            labels.append(image)\n",
    "            data.append(augment(image))\n",
    "    assert len(data) == len(labels), 'Length of data and labels does not match: {} vs {}'.format(len(data), len(labels))\n",
    "    return (data, labels)\n",
    "\n",
    "\n",
    "# Quickly display a card\n",
    "def display_card(image, size=(12,16)):\n",
    "    fig, ax = plt.subplots(figsize=size)\n",
    "    ax.imshow(random_contrast(image, 0.5, 3))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tfrecords(datapath, setcode):\n",
    "    with tf.io.TFRecordWriter('{}.tfrecords'.format(setcode)) as writer:\n",
    "        cards = os.listdir(os.path.join(datapath, setcode))\n",
    "        labels = [i for i in range(len(cards))]\n",
    "\n",
    "        for path, label in zip(cards, labels):\n",
    "            image = Image.open(os.path.join(datapath, setcode, path))\n",
    "            bytes_buffer = io.BytesIO()\n",
    "            image.convert('RGB').save(bytes_buffer, 'JPEG')\n",
    "            image_bytes = bytes_buffer.getvalue()\n",
    "\n",
    "            bytes_feature = tf.train.Feature(bytes_list = tf.train.BytesList(value=[image_bytes]))\n",
    "            class_feature = tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "\n",
    "            example = tf.train.Example(\n",
    "                features = tf.train.Features(feature={\n",
    "                    'image': bytes_feature,\n",
    "                    'class': class_feature\n",
    "                })\n",
    "            )\n",
    "            writer.write(example.SerializeToString())\n",
    "            image.close()\n",
    "\n",
    "image_feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "    \"class\": tf.io.FixedLenFeature([], tf.int64), \n",
    "    }\n",
    "\n",
    "def _parse_data(unparsed_example):\n",
    "    return tf.io.parse_single_example(unparsed_example, image_feature_description)\n",
    "\n",
    "def _bytestring_to_pixels(parsed_example):\n",
    "    byte_string = parsed_example['image']\n",
    "    image = tf.io.decode_image(byte_string)\n",
    "    image = tf.reshape(image, [256, 256, 3])\n",
    "    return image, parsed_example[\"class\"]\n",
    "\n",
    "def load_and_extract_images(filepath):\n",
    "    dataset = tf.data.TFRecordDataset(filepath)\n",
    "    dataset = dataset.map(_parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.map(_bytestring_to_pixels, num_parallel_calls=AUTOTUNE) # .cache()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_tfrecords(data_path, 'khm')\n",
    "ds_train = load_and_extract_images('khm.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ParallelMapDataset shapes: ((256, 256, 3), ()), types: (tf.uint8, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "print(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_card(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickly test dataset generation\n",
    "\n",
    "height = 1040\n",
    "width = 745\n",
    "\n",
    "model = ks.Sequential([\n",
    "    layers.Input((height, width, 3)),\n",
    "    layers.Conv2D(16, 3, padding='same'),\n",
    "    layers.Conv2D(32, 3, padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_directory(datadir):\n",
    "    files = os.listdir(datadir)\n",
    "    training_data = []\n",
    "    for i,f in enumerate(files):\n",
    "        filepath = os.path.join(datadir, f)\n",
    "        img_array = ski.imread(filepath)\n",
    "        training_data.append([img_array, i])\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = create_dataset_from_directory(os.path.join(data_path, 'khm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ks.preprocessing.image_dataset_from_directory(\n",
    "    '/mnt/d/cardimagescans/khm',\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = 8,\n",
    "    image_size = (height, width),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.1,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "ds_train.map(augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = make_dataset(['khm'], data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_path = os.path.join(data_path, 'khm')\n",
    "test_set = os.listdir(test_set_path)\n",
    "test_img = cv2.imread(os.path.join(test_set_path, test_set[69]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted = random_contrast(test_img)\n",
    "print(shifted.shape)\n",
    "display_card(shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_card_set = augment(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, card in enumerate(single_card_set):\n",
    "    if i%9==0:\n",
    "        display_card(card, (3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,16))\n",
    "ax.imshow(random_contrast(test_img, 0.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(set_dict.get('bfz')))\n",
    "for k in set_dict.keys():\n",
    "    s =  np.array(set_dict.get(k))\n",
    "    h = set(s[:,0])\n",
    "    w = set(s[:,1])\n",
    "    print(k, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a07be377b96d9253e4aa960188004583a7778b7453cac0e090bec1a451b774b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('cardrecognition')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as ks\n",
    "import os\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.python.data.experimental import AUTOTUNE\n",
    "\n",
    "from tripletdataset import TripletDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_image(image_path):\n",
    "#     img = tf.io.read_file(image_path)\n",
    "#     img = tf.image.decode_png(img, channels=3)\n",
    "#     img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "#     img = tf.image.resize(img, (385, 275))\n",
    "#     return img\n",
    "\n",
    "def preprocess(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, (385, 275))\n",
    "    img = tf.image.random_brightness(img, max_delta=0.6)\n",
    "    img = tf.image.random_contrast(img, 0.2, 3.0)\n",
    "    img = tf.image.random_jpeg_quality(img, 20, 80)\n",
    "    #img = gaussian(img, sigma=np.random.choice(range(1,4)))\n",
    "    img = tf.clip_by_value(img, 0.0, 1.0)\n",
    "    img = tf.image.random_crop(img, [350, 250, 3])\n",
    "    return img\n",
    "\n",
    "def preprocess_triplet(anchor, positive, negative):\n",
    "    return (\n",
    "        preprocess(anchor),\n",
    "        preprocess(positive),\n",
    "        preprocess(negative)\n",
    "    )\n",
    "\n",
    "def get_card_paths(root_path, set_codes):\n",
    "    card_paths = []\n",
    "    print(root_path, set_codes)\n",
    "    for s in set_codes:\n",
    "        assert os.path.exists(os.path.join(root_path, s)), \\\n",
    "            'Error: path {} does not exist'.format(os.path.join(root_path, s))\n",
    "        set_path = os.listdir(os.path.join(root_path, s))\n",
    "        for card in set_path:\n",
    "            card_paths.append(os.path.join(root_path, s, card))\n",
    "    return card_paths\n",
    "\n",
    "def visualize(anchor, positive, negative):\n",
    "    \"\"\"Visualize a few triplets from the supplied batches.\"\"\"\n",
    "\n",
    "    def show(ax, image):\n",
    "        ax.imshow(image)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "\n",
    "    axs = fig.subplots(3, 3)\n",
    "    for i in range(3):\n",
    "        show(axs[i, 0], anchor[i])\n",
    "        show(axs[i, 1], positive[i])\n",
    "        show(axs[i, 2], negative[i])\n",
    "\n",
    "root_path = '/mnt/d/cardimagescans'\n",
    "set_codes = ['khm', 'isd', 'sta', 'ogw', 'soi', 'ori', 'znr', 'lgn', 'plc', 'inv']\n",
    "#set_codes = ['khm']\n",
    "img_paths = get_card_paths(root_path, set_codes)\n",
    "image_counts = len(img_paths)\n",
    "\n",
    "anchor_dataset = tf.data.Dataset.from_tensor_slices(img_paths)\n",
    "positive_dataset = tf.data.Dataset.from_tensor_slices(img_paths)\n",
    "np.random.shuffle(img_paths)\n",
    "negative_dataset = tf.data.Dataset.from_tensor_slices(img_paths)\n",
    "negative_dataset = negative_dataset.shuffle(buffer_size=1024)\n",
    "dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "dataset = dataset.map(preprocess_triplet, num_parallel_calls=4)\n",
    "\n",
    "train_dataset = dataset.take(round(image_counts * 0.8))\n",
    "val_dataset = dataset.skip(round(image_counts * 0.8))\n",
    "\n",
    "train_dataset = train_dataset.batch(8, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(4)\n",
    "\n",
    "val_dataset = val_dataset.batch(8, drop_remainder=False)\n",
    "val_dataset = val_dataset.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(*list(train_dataset.take(1).as_numpy_iterator())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a triplet loss model the Keras way\n",
    "input_shape=(350,250,3)\n",
    "\n",
    "class DistanceLayer(ks.layers.Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        distance_ap = tf.reduce_sum(tf.square(anchor-positive), -1)\n",
    "        distance_an = tf.reduce_sum(tf.square(anchor-negative), -1)\n",
    "        return (distance_ap, distance_an)\n",
    "\n",
    "class SiameseModel(ks.Model):\n",
    "\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = ks.metrics.Mean(name='loss')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "        \n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {'loss':self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {'loss': self.loss_tracker.result()}\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "\n",
    "        loss = tf.maximum(ap_distance - an_distance + self.margin, 0.0)\n",
    "        return loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]\n",
    "\n",
    "\n",
    "vgg = ks.applications.VGG19(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape,\n",
    "        pooling='max'\n",
    "    )\n",
    "\n",
    "flatten = ks.layers.Flatten()(vgg.output)\n",
    "dense1 = ks.layers.Dense(512, activation='relu')(flatten)\n",
    "dense1 = ks.layers.BatchNormalization()(dense1)\n",
    "dense2 = ks.layers.Dense(256, activation='relu')(dense1)\n",
    "dense2 = ks.layers.BatchNormalization()(dense2)\n",
    "output = ks.layers.Dense(256, activation='relu')(dense2)\n",
    "\n",
    "encoder = ks.Model(vgg.input, output, name='Encoder')\n",
    "\n",
    "input_a = ks.layers.Input(name='anchor_input', shape=input_shape)\n",
    "#input_a = tf.expand_dims(input_a, axis=-4)\n",
    "input_p = ks.layers.Input(name='positive_input', shape=input_shape)\n",
    "#input_p = tf.expand_dims(input_p, axis=-4)\n",
    "input_n = ks.layers.Input(name='negative_input', shape=input_shape)\n",
    "#input_n = tf.expand_dims(input_n, axis=-4)\n",
    "\n",
    "distances = DistanceLayer()(\n",
    "    encoder(input_a),\n",
    "    encoder(input_p),\n",
    "    encoder(input_n),\n",
    ")\n",
    "\n",
    "siamese_network = ks.Model(\n",
    "    inputs=[input_a, input_p, input_n],\n",
    "    outputs=distances\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = SiameseModel(siamese_network)\n",
    "siamese_model.compile(optimizer=ks.optimizers.Adam(0.0001))\n",
    "siamese_model.fit(train_dataset, epochs=20, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks.utils.plot_model(vgg, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = dataset.get_triplet_batch()\n",
    "print(np.shape(dummy_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy_data = dataset.get_batch_list()\n",
    "siamese_model.fit(dataset.get_triplet_batch(), epochs=20, validation_data=dataset.get_triplet_batch(train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "# triplet model from scratch\n",
    "def tripletloss(model_anchor, model_positive, model_negative, margin=0.5):\n",
    "    distance1 = tf.sqrt(tf.reduce_mean(tf.pow(model_anchor - model_positive, 2), 1, keepdims=True))\n",
    "    distance2 = tf.sqrt(tf.reduce_mean(tf.pow(model_anchor - model_negative, 2), 1, keepdims=True))\n",
    "    return tf.reduce_mean(tf.maximum(distance1 - distance2 + margin, 0))\n",
    "\n",
    "def tripletloss_wrapper(loss_list, margin = 0.5):\n",
    "    return (tripletloss(loss_list[0], loss_list[1], loss_list[2], margin))\n",
    "\n",
    "def get_siamese_net(input_shape):\n",
    "    input_a = ks.Input(shape=input_shape)\n",
    "    input_p = ks.Input(shape=input_shape)\n",
    "    input_n = ks.Input(shape=input_shape)\n",
    "\n",
    "    vgg = ks.applications.VGG19(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape,\n",
    "        pooling='max'\n",
    "    )\n",
    "\n",
    "    flatten = ks.layers.Flatten()\n",
    "    encoder = ks.layers.Dense(265, activation='relu')\n",
    "\n",
    "    encoded_a = vgg(input_a)\n",
    "    encoded_a = flatten(encoded_a)\n",
    "    encoded_a = encoder(encoded_a)\n",
    "\n",
    "    encoded_p = vgg(input_p)\n",
    "    encoded_p = flatten(encoded_p)\n",
    "    encoded_p = encoder(encoded_p)\n",
    "\n",
    "    encoded_n = vgg(input_n)\n",
    "    encoded_n = flatten(encoded_n)\n",
    "    encoded_n = encoder(encoded_n)\n",
    "\n",
    "    Distance_layer_ap = ks.layers.Lambda(lambda x: tf.sqrt(tf.reduce_mean(tf.pow(x[0] - x[1], 2), 1, keepdims=True)))\n",
    "    Distance_layer_an = ks.layers.Lambda(lambda x: tf.sqrt(tf.reduce_mean(tf.pow(x[0] - x[1], 2), 1, keepdims=True)))\n",
    "    distance_ap = Distance_layer_ap([encoded_a, encoded_p])\n",
    "    distance_an = Distance_layer_an([encoded_a, encoded_n])\n",
    "\n",
    "    siamese_net = ks.Model(inputs=(input_a, input_p, input_n), outputs=(distance_ap, distance_an))\n",
    "    return siamese_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_siamese_net((350,250,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks.utils.plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = np.random.normal(size=(3, 350, 250,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(dummy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_net(input_size):\n",
    "#input_size = [350, 250, 3]\n",
    "    anker_input = ks.Input(input_size)\n",
    "    positive_input = ks.Input(input_size)\n",
    "    negative_input = ks.Input(input_size)\n",
    "\n",
    "    vgg = ks.applications.VGG16(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_size,\n",
    "        pooling='max'\n",
    "    )\n",
    "\n",
    "    encoder_layer = ks.layers.Dense(256, activation='relu')(vgg)\n",
    "\n",
    "    encoded_anker = model(anker_input)\n",
    "    encoded_positive = model(positive_input)\n",
    "    encoded_negative = model(negative_input)\n",
    "\n",
    "    Distance_Layer = ks.layers.Lambda(lambda x: tripletloss_wrapper(x))\n",
    "    triplet_loss = Distance_Layer([encoded_anker, encoded_positive, encoded_negative])\n",
    "\n",
    "    similarity = ks.layers.Dense(1, activation='sigmoid')(triplet_loss)\n",
    "\n",
    "    siamese_net = ks.Model(inputs=[anker_input, positive_input, negative_input], outputs=similarity)\n",
    "\n",
    "    return siamese_net\n",
    "\n",
    "#encoder_layer = ks.layers.Dense(265, activation='relu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tripletloss(model_anchor, model_positive, model_negative, margin=0.5):\n",
    "    distance1 = tf.sqrt(tf.reduce_mean(tf.pow(model_anchor - model_positive, 2), 1, keepdims=True))\n",
    "    distance2 = tf.sqrt(tf.reduce_mean(tf.pow(model_anchor - model_negative, 2), 1, keepdims=True))\n",
    "    return tf.reduce_mean(tf.maximum(distance1 - distance2 + margin, 0))\n",
    "\n",
    "def tripletloss_wrapper(loss_list, margin = 0.5):\n",
    "    return (tripletloss(loss_list[0], loss_list[1], loss_list[2], margin))\n",
    "\n",
    "def make_triplet_loss_network(input_size):\n",
    "    \n",
    "    input_anker = ks.Input(input_size)\n",
    "    input_positive = ks.Input(input_size)\n",
    "    input_negative = ks.Input(input_size)\n",
    "\n",
    "    model = ks.Sequential()\n",
    "    model.add(\n",
    "        ks.applications.VGG16(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=input_size,\n",
    "            pooling='max'\n",
    "    )\n",
    "    )\n",
    "    model.add(ks.layers.Flatten())\n",
    "    model.add(ks.layers.Dense(256, activation='sigmoid'))\n",
    "\n",
    "    encoded_anker = model(input_anker)\n",
    "    encoded_positive = model(input_positive)\n",
    "    encoded_negative = model(input_negative)\n",
    "\n",
    "    triplet_model = ks.Model(inputs=[input_anker, input_positive, input_negative], outputs=[encoded_anker, encoded_positive, encoded_negative])\n",
    "\n",
    "    #loss = tripletloss(encoded_anker, encoded_positive, encoded_negative)\n",
    "\n",
    "    \n",
    "\n",
    "    # similarity_layer = ks.layers.Lambda(lambda x: tripletloss(x[0], x[1], x[2]))\n",
    "    # similarity_score = similarity_layer([encoded_anker, encoded_positive, encoded_negative])\n",
    "\n",
    "    return triplet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model = make_triplet_loss_network([350,250,3])\n",
    "\n",
    "triplet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet = dataset.get_batch_list()\n",
    "\n",
    "len(triplet[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model.fit(x=dataset.get_batch_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_triplet_loss_network([350,250,3])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anker, positive, negative = dataset.get_triplet()\n",
    "\n",
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tfrecords dataset\n",
    "image_feature_description = {\n",
    "    \"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "    \"class\": tf.io.FixedLenFeature([], tf.int64), \n",
    "    }\n",
    "\n",
    "def _parse_data(unparsed_example):\n",
    "    return tf.io.parse_single_example(unparsed_example, image_feature_description)\n",
    "\n",
    "def _bytestring_to_pixels(parsed_example):\n",
    "    byte_string = parsed_example['image']\n",
    "    image = tf.io.decode_image(byte_string)\n",
    "    image = tf.reshape(image, input_shape)\n",
    "    return image, parsed_example[\"class\"]\n",
    "\n",
    "def load_and_extract_images(filepath):\n",
    "    dataset = tf.data.TFRecordDataset(filepath)\n",
    "    dataset = dataset.map(_parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.map(_bytestring_to_pixels, num_parallel_calls=AUTOTUNE) # .cache()\n",
    "    return dataset\n",
    "\n",
    "def tripletloss(model_anchor, model_positive, model_negative, margin=2):\n",
    "    distance1 = tf.sqrt(tf.reduce_mean(tf.pow(model_anchor - model_positive, 2), 1, keepdims=True))\n",
    "    distance2 = tf.sqrt(tf.reduce_mean(tf.pow(model_anchor - model_negative, 2), 1, keepdims=True))\n",
    "    return tf.reduce_mean(tf.maximum(distance1 - distance2 + margin, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_and_extract_images(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_input_fn(dataset):\n",
    "    double_set = tf.data.Dataset(dataset.batch(2))\n",
    "    return double_set\n",
    "\n",
    "triplet_set = triplet_input_fn(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "test_set = train_dataset.take(1)\n",
    "for image, label in test_set:\n",
    "    print(image.shape)\n",
    "    imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = ks.Sequential()\n",
    "convnet.add(ks.layers.Input(input_shape))\n",
    "convnet.add(ks.layers.Conv2D(32, [7,7]))\n",
    "convnet.add(ks.layers.MaxPool2D())\n",
    "convnet.add(ks.layers.Conv2D(64, [5,5]))\n",
    "convnet.add(ks.layers.MaxPool2D())\n",
    "convnet.add(ks.layers.Conv2D(128, [3,3]))\n",
    "convnet.add(ks.layers.MaxPool2D())\n",
    "convnet.add(ks.layers.Flatten())\n",
    "convnet.add(ks.layers.Dense(256, activation=None))\n",
    "convnet.add(ks.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet.compile(optimizer='Adam', loss=tripletloss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    convnet.fit(dataset, batch_size=8)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a07be377b96d9253e4aa960188004583a7778b7453cac0e090bec1a451b774b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('cardrecognition')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
